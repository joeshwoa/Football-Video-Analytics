{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# [N2-C01] Install\n!pip -q install ultralytics==8.4.11 opencv-python pandas pyarrow","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:31:33.764566Z","iopub.execute_input":"2026-02-05T18:31:33.764940Z","iopub.status.idle":"2026-02-05T18:31:39.885011Z","shell.execute_reply.started":"2026-02-05T18:31:33.764912Z","shell.execute_reply":"2026-02-05T18:31:39.883988Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# [N2-C02] Paths (your model + your video)\nimport os\n\nMODEL_PATH = \"/kaggle/input/football-yolov8m-plrglkprrefball-4-class/pytorch/default/1/best.pt\"\nVIDEO_PATH = \"/kaggle/input/football-match-sample/sample.mp4\"\n\nassert os.path.exists(MODEL_PATH), MODEL_PATH\nassert os.path.exists(VIDEO_PATH), VIDEO_PATH\n\nprint(\"MODEL_PATH:\", MODEL_PATH)\nprint(\"VIDEO_PATH:\", VIDEO_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:31:39.886991Z","iopub.execute_input":"2026-02-05T18:31:39.887878Z","iopub.status.idle":"2026-02-05T18:31:39.895278Z","shell.execute_reply.started":"2026-02-05T18:31:39.887834Z","shell.execute_reply":"2026-02-05T18:31:39.894583Z"}},"outputs":[{"name":"stdout","text":"MODEL_PATH: /kaggle/input/football-yolov8m-plrglkprrefball-4-class/pytorch/default/1/best.pt\nVIDEO_PATH: /kaggle/input/football-match-sample/sample.mp4\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# [N2-C03] Run tracking and collect per-frame detections\n# This creates a table with: frame, track_id, cls, conf, xyxy.\nimport pandas as pd\nfrom ultralytics import YOLO\n\nmodel = YOLO(MODEL_PATH)\n\nrows = []\nframe_idx = 0\n\n# stream=True gives you results frame-by-frame\nfor r in model.track(\n    source=VIDEO_PATH,\n    tracker=\"bytetrack.yaml\",   # try \"botsort.yaml\" later if you want stronger ID persistence\n    conf=0.20,\n    iou=0.50,\n    imgsz=960,\n    persist=True,\n    stream=True,\n    verbose=False\n):\n    boxes = r.boxes\n    if boxes is None or len(boxes) == 0:\n        frame_idx += 1\n        continue\n\n    xyxy = boxes.xyxy.cpu().numpy()\n    cls  = boxes.cls.cpu().numpy().astype(int)\n    conf = boxes.conf.cpu().numpy()\n    tid  = None if boxes.id is None else boxes.id.cpu().numpy().astype(int)\n\n    for i in range(len(xyxy)):\n        rows.append({\n            \"frame\": frame_idx,\n            \"track_id\": int(tid[i]) if tid is not None else -1,\n            \"cls\": int(cls[i]),\n            \"conf\": float(conf[i]),\n            \"x1\": float(xyxy[i][0]),\n            \"y1\": float(xyxy[i][1]),\n            \"x2\": float(xyxy[i][2]),\n            \"y2\": float(xyxy[i][3]),\n        })\n\n    frame_idx += 1\n\ndf = pd.DataFrame(rows)\nprint(df.head())\nprint(\"rows:\", len(df), \"frames:\", df[\"frame\"].nunique())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:31:39.896233Z","iopub.execute_input":"2026-02-05T18:31:39.896464Z","iopub.status.idle":"2026-02-05T18:32:08.149441Z","shell.execute_reply.started":"2026-02-05T18:31:39.896435Z","shell.execute_reply":"2026-02-05T18:32:08.148767Z"}},"outputs":[{"name":"stdout","text":"Creating new Ultralytics Settings v0.0.6 file ✅ \nView Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\nUpdate Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\nUsing Python 3.12.12 environment at: /usr\nResolved 2 packages in 257ms\nPrepared 1 package in 75ms\nInstalled 1 package in 3ms\n + lap==0.5.12\n\n\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.8s\nWARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n\n","output_type":"stream"},{"name":"stderr","text":"[aac @ 0x3f0a9700] Input buffer exhausted before END element found\n","output_type":"stream"},{"name":"stdout","text":"   frame  track_id  cls      conf           x1          y1           x2  \\\n0      0         1    0  0.907156   548.546631  388.484192   576.100525   \n1      0         2    0  0.904687   577.584229  333.184326   608.443970   \n2      0         3    0  0.903775   270.721527  312.516479   290.960785   \n3      0         4    0  0.903154   668.158813  483.364258   697.090759   \n4      0         5    0  0.899520  1065.475098  216.175598  1095.029175   \n\n           y2  \n0  441.450104  \n1  382.262115  \n2  361.712433  \n3  538.519897  \n4  256.805542  \nrows: 9578 frames: 449\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"# [N2-C04] Save raw tracks\nRAW_PATH = \"/kaggle/working/tracks_raw.parquet\"\ndf.to_parquet(RAW_PATH, index=False)\nprint(\"Saved:\", RAW_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:08.151279Z","iopub.execute_input":"2026-02-05T18:32:08.151704Z","iopub.status.idle":"2026-02-05T18:32:08.257101Z","shell.execute_reply.started":"2026-02-05T18:32:08.151673Z","shell.execute_reply":"2026-02-05T18:32:08.256431Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/tracks_raw.parquet\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# [N2-C05] Track-level class smoothing (majority vote weighted by confidence)\nimport numpy as np\nimport pandas as pd\n\nCLASS_NAMES = {0:\"player\", 1:\"goalkeeper\", 2:\"referee\", 3:\"ball\"}\n\n# Only smooth person-like classes; ball can be handled separately if desired\nPERSON_CLASSES = {0, 1, 2}\n\ndf_s = df.copy()\n\n# Compute a stable class per track_id using confidence-weighted voting\ntrack_best_cls = {}\nfor tid, g in df_s[df_s[\"track_id\"] >= 0].groupby(\"track_id\"):\n    # weighted vote per class\n    score = g.groupby(\"cls\")[\"conf\"].sum().to_dict()\n    best_cls = max(score, key=score.get)\n    track_best_cls[int(tid)] = int(best_cls)\n\n# Apply stable class back to all rows for that track\ndef stable_cls(row):\n    tid = int(row[\"track_id\"])\n    if tid >= 0 and tid in track_best_cls and int(row[\"cls\"]) in PERSON_CLASSES:\n        return track_best_cls[tid]\n    return int(row[\"cls\"])\n\ndf_s[\"cls_smooth\"] = df_s.apply(stable_cls, axis=1)\n\nprint(df_s[[\"track_id\",\"cls\",\"cls_smooth\"]].head(10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:08.258041Z","iopub.execute_input":"2026-02-05T18:32:08.258268Z","iopub.status.idle":"2026-02-05T18:32:08.442649Z","shell.execute_reply.started":"2026-02-05T18:32:08.258244Z","shell.execute_reply":"2026-02-05T18:32:08.441947Z"}},"outputs":[{"name":"stdout","text":"   track_id  cls  cls_smooth\n0         1    0           0\n1         2    0           0\n2         3    0           0\n3         4    0           0\n4         5    0           0\n5         6    0           0\n6         7    0           0\n7         8    0           0\n8         9    0           0\n9        10    0           0\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# [N2-C07] Write smoothed annotated video\nimport cv2\nfrom collections import defaultdict\n\nIN = VIDEO_PATH\nOUT = \"/kaggle/working/annotated_smoothed.mp4\"\n\ncap = cv2.VideoCapture(IN)\nfps = cap.get(cv2.CAP_PROP_FPS) or 25\nw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nwriter = cv2.VideoWriter(OUT, fourcc, fps, (w, h))\n\n# group detections by frame for fast lookup\nby_frame = {k: v for k, v in df_s.groupby(\"frame\")}\n\n# colors (BGR)\nCOLORS = {\n    0: (255, 0, 0),    # player - blue\n    1: (0, 255, 255),  # goalkeeper - yellow\n    2: (0, 165, 255),  # referee - orange\n    3: (0, 255, 0),    # ball - green\n}\n\nframe_i = 0\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n\n    if frame_i in by_frame:\n        g = by_frame[frame_i]\n        for _, row in g.iterrows():\n            cls = int(row[\"cls_smooth\"])\n            conf = float(row[\"conf\"])\n            x1,y1,x2,y2 = map(int, [row[\"x1\"],row[\"y1\"],row[\"x2\"],row[\"y2\"]])\n            tid = int(row[\"track_id\"])\n\n            color = COLORS.get(cls, (255,255,255))\n            cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n\n            # Reduce clutter: only show label if confidence is high enough\n            if conf >= 0.50:\n                label = f\"id:{tid} {CLASS_NAMES.get(cls,cls)} {conf:.2f}\"\n                cv2.putText(frame, label, (x1, max(15,y1-5)),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\n    writer.write(frame)\n    frame_i += 1\n\ncap.release()\nwriter.release()\n\nprint(\"Saved:\", OUT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:08.443885Z","iopub.execute_input":"2026-02-05T18:32:08.444253Z","iopub.status.idle":"2026-02-05T18:32:13.874015Z","shell.execute_reply.started":"2026-02-05T18:32:08.444209Z","shell.execute_reply":"2026-02-05T18:32:13.873141Z"}},"outputs":[{"name":"stderr","text":"[aac @ 0x5a5b4a40] Input buffer exhausted before END element found\n","output_type":"stream"},{"name":"stdout","text":"Saved: /kaggle/working/annotated_smoothed.mp4\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# [N2-C08] Save smoothed tracks\nSMOOTH_PATH = \"/kaggle/working/tracks_smoothed.parquet\"\ndf_s.to_parquet(SMOOTH_PATH, index=False)\nprint(\"Saved:\", SMOOTH_PATH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:13.875271Z","iopub.execute_input":"2026-02-05T18:32:13.875564Z","iopub.status.idle":"2026-02-05T18:32:13.892684Z","shell.execute_reply.started":"2026-02-05T18:32:13.875534Z","shell.execute_reply":"2026-02-05T18:32:13.891857Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/tracks_smoothed.parquet\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# [N2-C09] Install sklearn for KMeans\n!pip -q install scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:13.893779Z","iopub.execute_input":"2026-02-05T18:32:13.894105Z","iopub.status.idle":"2026-02-05T18:32:17.424968Z","shell.execute_reply.started":"2026-02-05T18:32:13.894075Z","shell.execute_reply":"2026-02-05T18:32:17.423855Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# [N2-C10-NEW] Robust per-track jersey features (Lab mean with grass removal)\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom collections import defaultdict\n\n# expects df_s exists and has: frame, track_id, cls_smooth, x1,y1,x2,y2\nassert \"cls_smooth\" in df_s.columns\n\nCLS_PLAYER, CLS_GK, CLS_REF, CLS_BALL = 0, 1, 2, 3\n\nFRAME_STRIDE = 2\nMAX_SAMPLES_PER_TRACK = 80\n\ncap = cv2.VideoCapture(VIDEO_PATH)\nok, frame0 = cap.read()\ncap.release()\nassert ok, \"Cannot read VIDEO_PATH\"\nH, W = frame0.shape[:2]\n\nby_frame = {k: v for k, v in df_s.groupby(\"frame\")}\n\n# accumulators: sum Lab + count of valid pixels\nlab_sum = defaultdict(lambda: np.zeros(3, dtype=np.float64))\nlab_cnt = defaultdict(int)\n\ndef clamp(v, lo, hi): \n    return max(lo, min(hi, v))\n\ndef crop_torso(frame, x1, y1, x2, y2):\n    \"\"\"\n    Torso crop for top-view:\n    - take top 55% of bbox\n    - take center 45% width to reduce grass/arms/shorts\n    \"\"\"\n    x1 = clamp(int(x1), 0, W-1); x2 = clamp(int(x2), 0, W-1)\n    y1 = clamp(int(y1), 0, H-1); y2 = clamp(int(y2), 0, H-1)\n    if x2 <= x1 or y2 <= y1:\n        return None\n\n    bw = x2 - x1\n    bh = y2 - y1\n\n    y2_t = y1 + int(0.55 * bh)\n    x1_c = x1 + int(0.275 * bw)\n    x2_c = x1 + int(0.725 * bw)\n\n    if y2_t <= y1 + 2 or x2_c <= x1_c + 2:\n        return None\n    crop = frame[y1:y2_t, x1_c:x2_c]\n    return crop if crop.size else None\n\ndef non_grass_mask(bgr_crop):\n    \"\"\"\n    mask out grass pixels using HSV threshold\n    \"\"\"\n    hsv = cv2.cvtColor(bgr_crop, cv2.COLOR_BGR2HSV)\n    lower = np.array([30, 30, 30])   # grass-ish\n    upper = np.array([95, 255, 255])\n    grass = cv2.inRange(hsv, lower, upper) > 0\n    return ~grass\n\ncap = cv2.VideoCapture(VIDEO_PATH)\nassert cap.isOpened(), \"Failed to open video\"\n\nframe_i = 0\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n    if frame_i % FRAME_STRIDE != 0:\n        frame_i += 1\n        continue\n\n    g = by_frame.get(frame_i, None)\n    if g is not None:\n        for _, r in g.iterrows():\n            tid = int(r[\"track_id\"])\n            if tid < 0:\n                continue\n            cls = int(r[\"cls_smooth\"])\n            if cls not in (CLS_PLAYER, CLS_GK, CLS_REF):   # ignore ball\n                continue\n            if lab_cnt[tid] >= MAX_SAMPLES_PER_TRACK:\n                continue\n\n            crop = crop_torso(frame, r[\"x1\"], r[\"y1\"], r[\"x2\"], r[\"y2\"])\n            if crop is None:\n                continue\n\n            mask = non_grass_mask(crop)\n            if mask.mean() < 0.10:\n                # too much grass -> skip this sample\n                continue\n\n            lab = cv2.cvtColor(crop, cv2.COLOR_BGR2LAB).astype(np.float32)\n            pixels = lab[mask]\n            if pixels.shape[0] < 30:\n                continue\n\n            mean_lab = pixels.mean(axis=0)  # (L,a,b)\n            lab_sum[tid] += mean_lab\n            lab_cnt[tid] += 1\n\n    frame_i += 1\n\ncap.release()\n\ntrack_ids = sorted([tid for tid, c in lab_cnt.items() if c > 0])\nX = np.stack([lab_sum[tid] / lab_cnt[tid] for tid in track_ids], axis=0)\n\nfeat_df = pd.DataFrame({\n    \"track_id\": track_ids,\n    \"n_samples\": [lab_cnt[tid] for tid in track_ids],\n    \"L\": X[:, 0], \"a\": X[:, 1], \"b\": X[:, 2]\n})\nprint(\"Tracks with jersey features:\", len(feat_df))\nfeat_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:17.426572Z","iopub.execute_input":"2026-02-05T18:32:17.426935Z","iopub.status.idle":"2026-02-05T18:32:18.992600Z","shell.execute_reply.started":"2026-02-05T18:32:17.426899Z","shell.execute_reply":"2026-02-05T18:32:18.991774Z"}},"outputs":[{"name":"stderr","text":"[aac @ 0x358d6cc0] Input buffer exhausted before END element found\n[aac @ 0x358d6cc0] Input buffer exhausted before END element found\n","output_type":"stream"},{"name":"stdout","text":"Tracks with jersey features: 77\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   track_id  n_samples           L           a           b\n0         1         20  234.471094  120.710394  130.556712\n1         2         18  104.198877  126.481853  157.100600\n2         4         80  225.472643  124.615981  125.758854\n3         5         80  101.535563  137.127912  153.434158\n4         6          6  208.058413  127.173448  121.981766","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>track_id</th>\n      <th>n_samples</th>\n      <th>L</th>\n      <th>a</th>\n      <th>b</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>20</td>\n      <td>234.471094</td>\n      <td>120.710394</td>\n      <td>130.556712</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>18</td>\n      <td>104.198877</td>\n      <td>126.481853</td>\n      <td>157.100600</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>80</td>\n      <td>225.472643</td>\n      <td>124.615981</td>\n      <td>125.758854</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5</td>\n      <td>80</td>\n      <td>101.535563</td>\n      <td>137.127912</td>\n      <td>153.434158</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>6</td>\n      <td>6</td>\n      <td>208.058413</td>\n      <td>127.173448</td>\n      <td>121.981766</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# [N2-C11-NEW] Cluster player tracks into 3 groups => 2 teams + referee-like cluster\nimport numpy as np\nimport pandas as pd\nfrom sklearn.cluster import KMeans\n\nCLS_PLAYER, CLS_GK, CLS_REF, CLS_BALL = 0, 1, 2, 3\n\n# dominant predicted class per track from df_s\ntrack_cls = (\n    df_s[df_s[\"track_id\"] >= 0]\n    .groupby(\"track_id\")[\"cls_smooth\"]\n    .agg(lambda s: int(s.mode().iloc[0]))\n    .to_dict()\n)\n\n# Use only tracks predicted as player for clustering (ref may be mispredicted as player)\nplayer_tids = [tid for tid in track_ids if track_cls.get(tid) == CLS_PLAYER]\n\nassert len(player_tids) >= 6, \"Not enough player tracks for clustering.\"\n\ntid_to_idx = {tid: i for i, tid in enumerate(track_ids)}\nXp = np.stack([X[tid_to_idx[tid]] for tid in player_tids], axis=0)\n\nkmeans3 = KMeans(n_clusters=3, random_state=0, n_init=\"auto\")\nlabels3 = kmeans3.fit_predict(Xp)\n\ntmp = pd.DataFrame({\"track_id\": player_tids, \"cluster\": labels3})\ncluster_sizes = tmp[\"cluster\"].value_counts().sort_values(ascending=False)\nprint(\"cluster sizes:\", cluster_sizes.to_dict())\n\n# take the TWO largest clusters as teams\nteam_clusters = list(cluster_sizes.index[:2])\nref_cluster = int(cluster_sizes.index[-1])  # smallest cluster\n\ntrack_team = {}      # track_id -> team_id {0,1} or -1 for referee\ntrack_role = {}      # track_id -> override role \"referee\"/\"player\"\n\n# Map cluster -> team_id (0/1)\ncluster_to_team = {team_clusters[0]: 0, team_clusters[1]: 1}\n\nfor tid, c in zip(player_tids, labels3):\n    c = int(c)\n    if c == ref_cluster:\n        track_team[tid] = -1\n        track_role[tid] = \"referee\"   # recover referee tracks\n    else:\n        track_team[tid] = cluster_to_team[c]\n        track_role[tid] = \"player\"\n\nprint(\"Recovered referee-like tracks:\", sum(1 for t in track_role.values() if t==\"referee\"))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:18.995179Z","iopub.execute_input":"2026-02-05T18:32:18.995499Z","iopub.status.idle":"2026-02-05T18:32:20.249292Z","shell.execute_reply.started":"2026-02-05T18:32:18.995473Z","shell.execute_reply":"2026-02-05T18:32:20.248470Z"}},"outputs":[{"name":"stdout","text":"cluster sizes: {0: 45, 1: 24, 2: 7}\nRecovered referee-like tracks: 7\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# [N2-C11b-NEW] Assign GK team using average x-position relative to team player centroids\nimport numpy as np\n\n# compute average x-center per track from df_s\ndf_s[\"xc\"] = (df_s[\"x1\"] + df_s[\"x2\"]) / 2.0\ntrack_xc = df_s[df_s[\"track_id\"] >= 0].groupby(\"track_id\")[\"xc\"].mean().to_dict()\n\n# team average x (using player tracks only that are assigned to teams)\nteam0_x = np.mean([track_xc[tid] for tid in track_team if track_team[tid] == 0 and tid in track_xc] or [W*0.25])\nteam1_x = np.mean([track_xc[tid] for tid in track_team if track_team[tid] == 1 and tid in track_xc] or [W*0.75])\n\ngk_tids = [tid for tid in track_ids if track_cls.get(tid) == CLS_GK]\nfor tid in gk_tids:\n    if tid not in track_xc:\n        continue\n    x = track_xc[tid]\n    # assign to nearest team x-centroid\n    track_team[tid] = 0 if abs(x - team0_x) <= abs(x - team1_x) else 1\n    track_role[tid] = \"goalkeeper\"\n\nprint(\"GK assigned:\", {tid: track_team.get(tid) for tid in gk_tids[:10]})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:20.250239Z","iopub.execute_input":"2026-02-05T18:32:20.250687Z","iopub.status.idle":"2026-02-05T18:32:20.271140Z","shell.execute_reply.started":"2026-02-05T18:32:20.250648Z","shell.execute_reply":"2026-02-05T18:32:20.270048Z"}},"outputs":[{"name":"stdout","text":"GK assigned: {}\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# [N2-C12-NEW] Build df_out with team + recovered referees\nimport pandas as pd\n\nCLASS_NAMES = {0:\"player\", 1:\"goalkeeper\", 2:\"referee\", 3:\"ball\"}\n\ndf_out = df_s.copy()\n\n# apply recovered referee role (override cls_smooth)\ndef apply_role(row):\n    tid = int(row[\"track_id\"])\n    if tid >= 0 and track_role.get(tid) == \"referee\":\n        return 2  # referee\n    return int(row[\"cls_smooth\"])\n\ndf_out[\"cls_final\"] = df_out.apply(apply_role, axis=1)\n\n# team assignment: referee=-1, ball=None\ndef apply_team(row):\n    tid = int(row[\"track_id\"])\n    cls = int(row[\"cls_final\"])\n    if cls == 3:      # ball\n        return None\n    if cls == 2:      # referee\n        return -1\n    return track_team.get(tid, None)\n\ndf_out[\"team_id\"] = df_out.apply(apply_team, axis=1)\ndf_out[\"class_name\"] = df_out[\"cls_final\"].map(CLASS_NAMES)\n\ndf_out[\"team_name\"] = df_out[\"team_id\"].map({0:\"team_A\", 1:\"team_B\", -1:\"referee\"}).fillna(\"unknown\")\n\ndf_out.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:20.273167Z","iopub.execute_input":"2026-02-05T18:32:20.274156Z","iopub.status.idle":"2026-02-05T18:32:20.471236Z","shell.execute_reply.started":"2026-02-05T18:32:20.274107Z","shell.execute_reply":"2026-02-05T18:32:20.470424Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"   frame  track_id  cls      conf           x1          y1           x2  \\\n0      0         1    0  0.907156   548.546631  388.484192   576.100525   \n1      0         2    0  0.904687   577.584229  333.184326   608.443970   \n2      0         3    0  0.903775   270.721527  312.516479   290.960785   \n3      0         4    0  0.903154   668.158813  483.364258   697.090759   \n4      0         5    0  0.899520  1065.475098  216.175598  1095.029175   \n\n           y2  cls_smooth           xc  cls_final  team_id class_name  \\\n0  441.450104           0   562.323578          0      0.0     player   \n1  382.262115           0   593.014099          0      1.0     player   \n2  361.712433           0   280.841156          0      NaN     player   \n3  538.519897           0   682.624786          0      0.0     player   \n4  256.805542           0  1080.252136          0      1.0     player   \n\n  team_name  \n0    team_A  \n1    team_B  \n2   unknown  \n3    team_A  \n4    team_B  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>frame</th>\n      <th>track_id</th>\n      <th>cls</th>\n      <th>conf</th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>cls_smooth</th>\n      <th>xc</th>\n      <th>cls_final</th>\n      <th>team_id</th>\n      <th>class_name</th>\n      <th>team_name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.907156</td>\n      <td>548.546631</td>\n      <td>388.484192</td>\n      <td>576.100525</td>\n      <td>441.450104</td>\n      <td>0</td>\n      <td>562.323578</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>player</td>\n      <td>team_A</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0.904687</td>\n      <td>577.584229</td>\n      <td>333.184326</td>\n      <td>608.443970</td>\n      <td>382.262115</td>\n      <td>0</td>\n      <td>593.014099</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>player</td>\n      <td>team_B</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0.903775</td>\n      <td>270.721527</td>\n      <td>312.516479</td>\n      <td>290.960785</td>\n      <td>361.712433</td>\n      <td>0</td>\n      <td>280.841156</td>\n      <td>0</td>\n      <td>NaN</td>\n      <td>player</td>\n      <td>unknown</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0.903154</td>\n      <td>668.158813</td>\n      <td>483.364258</td>\n      <td>697.090759</td>\n      <td>538.519897</td>\n      <td>0</td>\n      <td>682.624786</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>player</td>\n      <td>team_A</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0.899520</td>\n      <td>1065.475098</td>\n      <td>216.175598</td>\n      <td>1095.029175</td>\n      <td>256.805542</td>\n      <td>0</td>\n      <td>1080.252136</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>player</td>\n      <td>team_B</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# [N2-C13] Optional: render annotated video with TEAM colors\nimport cv2\n\nIN = VIDEO_PATH\nOUT = \"/kaggle/working/annotated_team.mp4\"\n\ncap = cv2.VideoCapture(IN)\nfps = cap.get(cv2.CAP_PROP_FPS) or 25\nw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nwriter = cv2.VideoWriter(OUT, fourcc, fps, (w, h))\n\nby_frame2 = {k: v for k, v in df_out.groupby(\"frame\")}\n\n# Team colors (BGR)\nTEAM_COLOR = {\n    \"team_A\": (0, 0, 255),    # red\n    \"team_B\": (255, 0, 0),    # blue\n    \"referee\": (0, 165, 255), # orange\n    \"unknown\": (200, 200, 200),\n}\nBALL_COLOR = (0, 255, 0)\n\nframe_i = 0\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n\n    g = by_frame2.get(frame_i, None)\n    if g is not None:\n        for _, row in g.iterrows():\n            cls = int(row[\"cls_smooth\"])\n            conf = float(row[\"conf\"])\n            x1,y1,x2,y2 = map(int, [row[\"x1\"],row[\"y1\"],row[\"x2\"],row[\"y2\"]])\n            tid = int(row[\"track_id\"])\n\n            if cls == CLS_BALL:\n                color = BALL_COLOR\n                label = f\"ball {conf:.2f}\"\n            else:\n                team_name = row[\"team_name\"]\n                color = TEAM_COLOR.get(team_name, TEAM_COLOR[\"unknown\"])\n                label = f\"id:{tid} {row['class_name']} {team_name} {conf:.2f}\"\n\n            cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n            if conf >= 0.50:\n                cv2.putText(frame, label, (x1, max(15,y1-5)),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\n    writer.write(frame)\n    frame_i += 1\n\ncap.release()\nwriter.release()\nprint(\"Saved:\", OUT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:20.472359Z","iopub.execute_input":"2026-02-05T18:32:20.472813Z","iopub.status.idle":"2026-02-05T18:32:26.227547Z","shell.execute_reply.started":"2026-02-05T18:32:20.472774Z","shell.execute_reply":"2026-02-05T18:32:26.226662Z"}},"outputs":[{"name":"stderr","text":"[aac @ 0x5dbe5880] Input buffer exhausted before END element found\n","output_type":"stream"},{"name":"stdout","text":"Saved: /kaggle/working/annotated_team.mp4\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"# [N2-C14] Recommended tracking settings (use these in your tracking cell)\nTRACKER_NAME = \"botsort.yaml\"  # better ID persistence than bytetrack in many cases\nINFER_IMGSZ = 1280             # helps small/blurred players and ball (slower)\nINFER_CONF = 0.15              # lower conf improves recall; smoothing/gap-fill will handle jitter\nINFER_IOU  = 0.50","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:26.228665Z","iopub.execute_input":"2026-02-05T18:32:26.229074Z","iopub.status.idle":"2026-02-05T18:32:26.233243Z","shell.execute_reply.started":"2026-02-05T18:32:26.229046Z","shell.execute_reply":"2026-02-05T18:32:26.232401Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# [N2-C15] Gap fill config (short gaps only)\nMAX_GAP_PERSON = 8   # players/goalkeepers/referees\nMAX_GAP_BALL   = 4   # ball changes fast; fill fewer frames","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:32:26.234426Z","iopub.execute_input":"2026-02-05T18:32:26.234699Z","iopub.status.idle":"2026-02-05T18:32:26.246693Z","shell.execute_reply.started":"2026-02-05T18:32:26.234663Z","shell.execute_reply":"2026-02-05T18:32:26.245977Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# [N2-C16-FIX] Gap fill preserving cls_final + team fields (safe mode)\nimport numpy as np\nimport pandas as pd\n\nCLASS_NAMES = {0:\"player\", 1:\"goalkeeper\", 2:\"referee\", 3:\"ball\"}\n\ndef _best_per_frame(g: pd.DataFrame) -> pd.DataFrame:\n    return g.sort_values(\"conf\", ascending=False).drop_duplicates([\"track_id\", \"frame\"], keep=\"first\")\n\ndef safe_mode(s: pd.Series, default=None):\n    \"\"\"Mode that handles all-NaN/all-None series.\"\"\"\n    if s is None:\n        return default\n    s2 = s.dropna()\n    if len(s2) == 0:\n        return default\n    m = s2.mode()\n    if len(m) == 0:\n        return default\n    return m.iloc[0]\n\ndef gap_fill_dense_with_team(df_in: pd.DataFrame, max_gap_person=8, max_gap_ball=4) -> pd.DataFrame:\n    df = df_in.copy()\n\n    # Ensure required columns exist\n    required = [\"frame\",\"track_id\",\"conf\",\"x1\",\"y1\",\"x2\",\"y2\",\"cls_final\"]\n    for c in required:\n        assert c in df.columns, f\"Missing required column: {c}\"\n\n    # Optional columns\n    if \"team_id\" not in df.columns:\n        df[\"team_id\"] = None\n    if \"team_name\" not in df.columns:\n        df[\"team_name\"] = \"unknown\"\n    if \"class_name\" not in df.columns:\n        df[\"class_name\"] = df[\"cls_final\"].map(CLASS_NAMES)\n\n    df = df[df[\"track_id\"].notna()].copy()\n    df[\"track_id\"] = df[\"track_id\"].astype(int)\n    df = df[df[\"track_id\"] >= 0].copy()\n\n    df = _best_per_frame(df)\n    df[\"is_interpolated\"] = False\n\n    out_parts = [df]\n\n    for tid, g in df.groupby(\"track_id\"):\n        g = g.sort_values(\"frame\").reset_index(drop=True)\n\n        cls_track = int(safe_mode(g[\"cls_final\"], default=int(g[\"cls_final\"].iloc[0])))\n        max_gap = max_gap_ball if cls_track == 3 else max_gap_person\n\n        team_id = safe_mode(g[\"team_id\"], default=None)\n        team_name = safe_mode(g[\"team_name\"], default=\"unknown\")\n        class_name = safe_mode(g[\"class_name\"], default=CLASS_NAMES.get(cls_track, str(cls_track)))\n\n        frames = g[\"frame\"].to_numpy()\n\n        for i in range(len(frames) - 1):\n            f1, f2 = int(frames[i]), int(frames[i + 1])\n            gap = f2 - f1 - 1\n            if gap <= 0 or gap > max_gap:\n                continue\n\n            r1 = g.iloc[i]\n            r2 = g.iloc[i + 1]\n\n            for k in range(1, gap + 1):\n                t = k / (gap + 1)\n\n                new = r1.to_dict()\n                new[\"frame\"] = f1 + k\n                new[\"x1\"] = float((1 - t) * r1[\"x1\"] + t * r2[\"x1\"])\n                new[\"y1\"] = float((1 - t) * r1[\"y1\"] + t * r2[\"y1\"])\n                new[\"x2\"] = float((1 - t) * r1[\"x2\"] + t * r2[\"x2\"])\n                new[\"y2\"] = float((1 - t) * r1[\"y2\"] + t * r2[\"y2\"])\n\n                new[\"conf\"] = float(min(float(r1[\"conf\"]), float(r2[\"conf\"])) * 0.50)\n\n                new[\"cls_final\"] = cls_track\n                new[\"team_id\"] = team_id\n                new[\"team_name\"] = team_name\n                new[\"class_name\"] = class_name\n\n                new[\"is_interpolated\"] = True\n                out_parts.append(pd.DataFrame([new]))\n\n    df_filled = pd.concat(out_parts, ignore_index=True)\n    df_filled = _best_per_frame(df_filled)\n    df_filled = df_filled.sort_values([\"frame\", \"track_id\"]).reset_index(drop=True)\n    return df_filled\n\ndf_final = gap_fill_dense_with_team(df_out, max_gap_person=8, max_gap_ball=4)\nprint(\"df_out rows:\", len(df_out), \"df_final rows:\", len(df_final))\nprint(\"Interpolated rows:\", int(df_final[\"is_interpolated\"].sum()))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:36:23.379893Z","iopub.execute_input":"2026-02-05T18:36:23.380624Z","iopub.status.idle":"2026-02-05T18:36:23.899453Z","shell.execute_reply.started":"2026-02-05T18:36:23.380593Z","shell.execute_reply":"2026-02-05T18:36:23.898621Z"}},"outputs":[{"name":"stdout","text":"df_out rows: 9578 df_final rows: 9880\nInterpolated rows: 302\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_55/266269803.py:88: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  df_filled = pd.concat(out_parts, ignore_index=True)\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"# [N2-C17] Export FINAL gap-filled table\nOUT_PARQUET = \"/kaggle/working/tracks_final.parquet\"\nOUT_CSV     = \"/kaggle/working/tracks_final.csv\"\n\ndf_final.to_parquet(OUT_PARQUET, index=False)\ndf_final.to_csv(OUT_CSV, index=False)\n\nprint(\"Saved:\", OUT_PARQUET)\nprint(\"Saved:\", OUT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:38:20.229565Z","iopub.execute_input":"2026-02-05T18:38:20.229967Z","iopub.status.idle":"2026-02-05T18:38:20.383958Z","shell.execute_reply.started":"2026-02-05T18:38:20.229934Z","shell.execute_reply":"2026-02-05T18:38:20.383267Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/tracks_final.parquet\nSaved: /kaggle/working/tracks_final.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# [N2-C18] Render video with gap-filled boxes (interpolated boxes drawn dashed color)\nimport cv2\n\nCLASS_NAMES = {0:\"player\", 1:\"goalkeeper\", 2:\"referee\", 3:\"ball\"}\n\nIN = VIDEO_PATH\nOUT = \"/kaggle/working/annotated_gapfilled.mp4\"\n\ncap = cv2.VideoCapture(IN)\nfps = cap.get(cv2.CAP_PROP_FPS) or 25\nw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nwriter = cv2.VideoWriter(OUT, fourcc, fps, (w, h))\n\nby_frame = {k: v for k, v in df_final.groupby(\"frame\")}\n\n# BGR colors\nCOLORS = {0:(255,0,0), 1:(0,255,255), 2:(0,165,255), 3:(0,255,0)}\nINTERP_COLOR = (180, 180, 180)  # gray for interpolated\n\nframe_i = 0\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n\n    g = by_frame.get(frame_i, None)\n    if g is not None:\n        for _, row in g.iterrows():\n            cls = int(row[\"cls_smooth\"]) if \"cls_smooth\" in row else int(row[\"cls\"])\n            tid = int(row[\"track_id\"])\n            conf = float(row[\"conf\"])\n            interp = bool(row.get(\"is_interpolated\", False))\n\n            x1,y1,x2,y2 = map(int, [row[\"x1\"],row[\"y1\"],row[\"x2\"],row[\"y2\"]])\n\n            color = INTERP_COLOR if interp else COLORS.get(cls, (255,255,255))\n            cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n\n            # show text only if not interpolated OR high confidence\n            if (not interp and conf >= 0.45) or (interp and conf >= 0.30):\n                label = f\"id:{tid} {CLASS_NAMES.get(cls,cls)} {conf:.2f}\"\n                cv2.putText(frame, label, (x1, max(15,y1-5)),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\n    writer.write(frame)\n    frame_i += 1\n\ncap.release()\nwriter.release()\nprint(\"Saved:\", OUT)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:38:52.869957Z","iopub.execute_input":"2026-02-05T18:38:52.870707Z","iopub.status.idle":"2026-02-05T18:38:58.255549Z","shell.execute_reply.started":"2026-02-05T18:38:52.870674Z","shell.execute_reply":"2026-02-05T18:38:58.254671Z"}},"outputs":[{"name":"stderr","text":"[aac @ 0x5edbdc40] Input buffer exhausted before END element found\n","output_type":"stream"},{"name":"stdout","text":"Saved: /kaggle/working/annotated_gapfilled.mp4\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# [N2-C19] FINAL VIDEO: everything applied\nimport cv2\n\nIN = VIDEO_PATH\nFINAL_VIDEO = \"/kaggle/working/final_result.mp4\"\n\ncap = cv2.VideoCapture(IN)\nfps = cap.get(cv2.CAP_PROP_FPS) or 25\nw = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nh = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nfourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\nwriter = cv2.VideoWriter(FINAL_VIDEO, fourcc, fps, (w, h))\n\nby_frame = {k: v for k, v in df_final.groupby(\"frame\")}\n\nTEAM_COLOR = {\n    \"team_A\": (0, 0, 255),    # red\n    \"team_B\": (255, 0, 0),    # blue\n    \"referee\": (0, 165, 255), # orange\n    \"unknown\": (200, 200, 200),\n}\nBALL_COLOR = (0, 255, 0)\nINTERP_COLOR = (180, 180, 180)\n\nframe_i = 0\nwhile True:\n    ok, frame = cap.read()\n    if not ok:\n        break\n\n    g = by_frame.get(frame_i, None)\n    if g is not None:\n        for _, r in g.iterrows():\n            cls = int(r[\"cls_final\"])\n            conf = float(r[\"conf\"])\n            interp = bool(r.get(\"is_interpolated\", False))\n            x1,y1,x2,y2 = map(int, [r[\"x1\"],r[\"y1\"],r[\"x2\"],r[\"y2\"]])\n\n            if cls == 3:\n                color = BALL_COLOR\n                label = f\"ball {conf:.2f}\"\n            else:\n                tn = r.get(\"team_name\", \"unknown\")\n                base_color = TEAM_COLOR.get(tn, TEAM_COLOR[\"unknown\"])\n                color = INTERP_COLOR if interp else base_color\n                tid = int(r[\"track_id\"])\n                label = f\"id:{tid} {r.get('class_name','?')} {tn} {conf:.2f}\"\n\n            cv2.rectangle(frame, (x1,y1), (x2,y2), color, 2)\n\n            # reduce text clutter\n            if (not interp and conf >= 0.45) or (interp and conf >= 0.30):\n                cv2.putText(frame, label, (x1, max(15, y1-5)),\n                            cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n\n    writer.write(frame)\n    frame_i += 1\n\ncap.release()\nwriter.release()\nprint(\"Saved FINAL video:\", FINAL_VIDEO)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:39:05.009091Z","iopub.execute_input":"2026-02-05T18:39:05.009903Z","iopub.status.idle":"2026-02-05T18:39:10.719461Z","shell.execute_reply.started":"2026-02-05T18:39:05.009871Z","shell.execute_reply":"2026-02-05T18:39:10.718761Z"}},"outputs":[{"name":"stderr","text":"[aac @ 0x5da64dc0] Input buffer exhausted before END element found\n","output_type":"stream"},{"name":"stdout","text":"Saved FINAL video: /kaggle/working/final_result.mp4\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"# [N2-C20] Export FINAL analytics table\nOUT_PARQUET = \"/kaggle/working/tracks_final.parquet\"\nOUT_CSV = \"/kaggle/working/tracks_final.csv\"\n\ndf_final.to_parquet(OUT_PARQUET, index=False)\ndf_final.to_csv(OUT_CSV, index=False)\n\nprint(\"Saved:\", OUT_PARQUET)\nprint(\"Saved:\", OUT_CSV)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-05T18:39:10.848329Z","iopub.execute_input":"2026-02-05T18:39:10.849033Z","iopub.status.idle":"2026-02-05T18:39:10.984324Z","shell.execute_reply.started":"2026-02-05T18:39:10.849000Z","shell.execute_reply":"2026-02-05T18:39:10.983485Z"}},"outputs":[{"name":"stdout","text":"Saved: /kaggle/working/tracks_final.parquet\nSaved: /kaggle/working/tracks_final.csv\n","output_type":"stream"}],"execution_count":23}]}